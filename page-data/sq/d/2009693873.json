{"data":{"jobs":{"edges":[{"node":{"frontmatter":{"title":"Data Science Intern","company":"Hewlett Packard Enterprise","location":"Remote","range":"July - September 2024","url":"https://www.hpe.com/us/en/home.html"},"html":"<ul>\n<li>\n<p>Engineered data pipelines in Python, cutting processing time by 20% and freeing up resources for higher-value tasks.</p>\n</li>\n<li>\n<p>Developed predictive models (Logistic Regression, Random Forest), boosting insight accuracy by 15%, enabling more informed business decisions.</p>\n</li>\n<li>\n<p>Built real-time dashboards in Power BI and Qlik, reducing reporting time by 25%, allowing teams to act on insights faster.</p>\n</li>\n<li>\n<p>Led pricing analysis by merging and exploring orders and quotes data, revealing key patterns that optimized regional pricing strategies.</p>\n</li>\n<li>\n<p>Presented actionable insights to stakeholders using Dataiku, refining win rate predictions and driving data-driven decisions across teams.</p>\n</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Graduate Engineer Trainee","company":"Pepsico Global Services","location":"Hyderabad","range":"July 2022 - Aug 2023","url":"https://www.pepsicoindia.co.in/"},"html":"<ul>\n<li>Orchestrated the development of ACQ and DWL tables in the Global PepsiCo Performance Drivers project using bteq scripts. Enabling more accurate performance metrics and contributing to a 15% increase in data accuracy.</li>\n<li>Led the end-to-end fulfillment of the IT Finance LATAM project by transferring data from SharePoint to DataLake, creating 12 tables across bronze, silver, and gold layers using Azure Databricks, PySpark, and Azure Data Factory, and enabling real-time business insights via Presto views, reducing reporting time by 20%.</li>\n<li>Spearheaded the development of tables in the DWL layer for the E2EWasteManagement project which helped the business to meticulously track wastage across various taxonomies.</li>\n</ul>"}}]}}}